\chapter[CONCLUSIONS AND FUTURE WORK]{\huge CONCLUSIONS AND FUTURE WORK}
In this chapter are described the conclusions associated with the particular objectives of this work. Due to that, each subsection is related to a particular objective. Hence, the most outstanding contributions from each step of the methodology followed (Figure \ref{Fig: Diagram}) are mentioned. Finally, the detected future works from the methodology steps are mentioned at the end of this chapter.

\section{Conclusions}
\subsection{Data Selection and Processing}
In chapter 4 was mentioned that all database's signals were revised and, consequently, some of them were discarded due to notorious periodicities presented on the signals. With this step was remarked the importance of revising the samples before performing experiments, despite the database's usage in previous works. Besides, more samples are required to obtain more significant results (here were used a subset of 543 from the initial amount of 1870), as well as a balance across the number of class samples is necessary.\\

Furthermore, the processing steps carried in this work were specific for each classification approach and mental activity samples. In the Vector-based approach, the processing was different for each mental activity. For overt speech samples, the signals were trimmed according to speech signals energy. Whereas, for imagined speech samples, two wavelet approaches (DWT and WPT) were used to perform a spectro-temporal analysis over the signals (due to the absence of external references). Besides, both wavelet approaches coincided with those EEG sub-bands described in the theoretical framework.\\

On the other hand, the processing step in the NeuCube (Spatio-temporal approach) was the same for both mental activities and consisted of encoding the EEG signals. This step was carried with optimization processes (grid search for SF and DEA for BSA) through the MSE measured with the signal's reconstruction. While the SSN did not require necessarily any processing step (just the preprocessed signals, and in the case of feature vectors, the same processing as in the Vector-based approach).\\

\subsection{Feature Extraction}

The features extracted from the signals were particular for each classification approach. In the case of the Vector-based approach, statistical features were computed from each signal's overlapped segment, and PCA was performed when wavelets were applied in the processing step to reduce the vector's dimensionality. These statistical features were input to the classifiers (MLP and SVM in this work) that cannot work with raw temporal data.\\

On the other hand, the feature extraction step in the NeuCube can be considered when the optimal encoding of the signal was obtained. While the SSN did not require any particular feature extraction since it accepted the input values (either features or signal's amplitude) each time step.\\


\subsection{Experimental Framework}
Next, the validation methodology followed in this work considered subject-independent experiments by holding one subject's data out from the rest per case. Hence, training and test scores were computed with data unseen previously by the trained classifiers, which provided unbiased results. Furthermore, several experiments with different initializations were performed for classifiers sensitive to the initial parameter's values (MLP and NeuCube in this work). Then, the average scores were computed to provide more reliable results.\\

\subsection{Classification Results Analysis}

In chapter 6 were shown all the overall accuracies obtained with each classifier, binary data set used, and subject's data held out from the rest for testing. Moreover, this information was presented by mental activity, classification approach, and features used (in the case of the Vector-based approach). Then, the best overall accuracies per case were selected to make a more in-depth analysis.\\

These best results proceeded from the $\pm$Bilabial data set and by the $SSN_{L}$ classifier. Hence, analysis over the $SSN_{L}$ results was carried, from which the best per mental activity were selected. For overt speech samples, the best scores were obtained with the Vector-based approach using 3 features, while for imagined speech were with the Spatio-temporal approach.\\

Then, the average was computed across training and test accuracies. For overt speech samples, the training and test accuracies were 73.66$\pm$1.56\% and 72.96$\pm$4.04\%. , respectively. While for imagined speech samples, the average accuracies from training and test data were 70.3$\pm$2.92\% and 76.81$\pm$8.31, respectively.\\

These results were lower than those reported in the previous works that used the database Kara One (above 90\% of accuracies, on average). However, they used the samples rejected in this work and were considered not examples of any mental activity. Hence, their periodicities aided to get similar features among the samples from the same class and, consequently, provided high scores.\\

Besides, the reported results in those works came from the most unbalanced binary classes: $\pm VC$ and $\pm /uw/$, which, as seen with the best results in this work, also aided to improve the accuracies. Additionally, in the case of the classifier that provided the best scores in those works (the DBN), it was not mentioned if several experiments with different initializations were performed, nor cross-validation for training scores as in this work.\\

On the other hand, comparing with other EEG-based works in the literature review, in this work were used classifiers that consider the temporal and spatial aspects of the data. In the Vector-based approach, the temporal information was extracted from each channel classifier (spatial aspect considered with them) and considered jointly with the decision rule, while in other related works, each channel data was averaged or concatenated, which masked each channel's contributions.\\

Hence, although the Pearson correlations between acoustic and imagined feature vectors were computed for the channel's selection in the previous works that used the Kara One database, a test to obtain the significance of these correlations were not carry (such as the Kolmogorov-Smirnoff test). While, in this work, a channel's selection methodology was carried based on the best resulting scores. Besides, in the Spatio-temporal approach, were used classifiers, based on spiking neurons, that had not been used before for overt and imagined speech samples.\\

To sum up, a methodology was carried with Vector-based approach classifiers to deal with spatial and temporal information. Hence, Spatio-temporal classifiers based on spiking neurons have been used by the first time with overt and imagined speech, from which the $SSN_{L}$ scores outperformed others with training and test accuracies above the chance in both mental activities. These results could represent the feasibility of overt and imagined speech classification. However, a more in-depth analysis showed that the unbalance between class samples aided to obtain high accuracy. For this reason, it is recommended to develop balanced databases in future works.

\section{Contributions}
The contributions from this work are listed as follows:
\begin{itemize}
	\item Nosy samples rejected and indicated from the database Kara One for future works.
	\item Overt speech classification experiments (these samples had not been used in other previous works with this database).
	\item Classification experiments with Vector-based and Spatio-temporal approaches.
	\item Wavelet decompositions with two approaches (DWT and WPT). Hence, MODWPT was used to avoid downsampling (data reduction).
	\item Score's comparisons between the 21 features described in the literature review, and a subset of these features.
	\item Wavelet feature's dimension reduced with PCA.
	\item Sub-bands selection by correlation rankings (not used in all the classification experiments due to low scores).
	\item A voting scheme for Vector-based classifiers.
	\item Channel's selection, per mental activity and classifier, based on channel's scores.
	\item Optimized EEG-signal's encodings with two different encoders (SF and BSA).
	\item Subject-independent classification with the NeuCube for the first time.
	\item Two different neuron models used with the SSN: LIF and Izhikevich.
	\item Two different input types for the SSN: feature vectors and EEG signals.
	\item A subject-independent validation methodology for all the classifiers, which avoided biased results by computing the scores from data not used in training.
	\item Average scores computed from several experiments with different initializations for classifiers sensitives to initial parameters.
	\item Parameters used in each classifier were shown to replicate the experiments.
	\item Classification results analysis through the accuracy, recall, precision, and F1 scores.
	\item An article (not summited yet) written during the research stay at the KEDRI lab from the AUT.
\end{itemize}

\section{Future Recommendations}
Due to the problems founded with the Kara One database, it is recommendable to create a new robust and balanced database, from which all samples were revised beforehand. Hence, more controlled data acquisition experiments are required, like those from \cite{stephanie}, in which the exact timing intervals of both mental activities were recognized due to the visual stimulations. Thus, the signals from both mental activities were shorter than those from the Kara One database. Also, wavelet decompositions would be applied for both mental activities independently of their lengths, if EEG signals were recorded with a lower Fs.\\

On the other hand, a more in-depth study in the preprocessing techniques for EEG signals is required to implement them in future works since there were not any contributions to this step in this work. ICA \cite{makeig1996independent} is a preprocessing method usually used. However, it is recommended to carry a well-based analysis of the resulting sources since overt and imagined speech phenomena currently are not entirely understood.\\

Moreover, wavelet decompositions were used in the processing step. However, the scores obtained with these techniques were low compared with no processed (imagined speech) signals. These results may reflect the inadequate mother wavelet selection because, as stated in the theoretical framework, a properly wavelet selection could provide optimum resolution of specific neuroelectric events. Hence, the matching pursuit method or matched Meyer wavelets (mentioned in \cite{samar1999wavelet}) are recommended for these data to create proper wavelets.\\

Then, in this work were explored just some statistical features and a subset from them. It is recommended to use other types, such as spectral features, in future works. Thus, a feature selection step could be useful to reduce the number of classification experiments. A bag of features can be used, similarly as in \cite{salinas2017bag}, as well as other methods to obtain the feature sets that maximize the distance between samples from different classes while minimizing the distance of samples from the same class.\\

Furthermore, other segment lengths and overlapping percentages could be tested, as in \cite{marek}. Due to that, other classifiers that consider temporal relationships could be used, such as the HMMs, which each could process a particular input channel data. Thus, each HMM could have transition states with the nearby HMMs, with which temporal and spatial aspects of the EEG data would be considered.\\

In the case of NeuCube, it was noticed how impractical an optimization process could be with all the samples (even that were just 543 in this work). However, a more in-depth analysis of the signals is necessary to develop an encoder adequate for these data. Also, just the LIF neuron model was used in the NeuCube for this work. Therefore, using other models could be useful to select the best for overt and imagined speech.\\

Then, although the SSN was the most analyzed classifier in this work (because it provided the best scores), it is still missing classification experiments with encoded EEG samples as inputs, similarly as in the NeuCube. These experiments could be relevant since these neuron models are based on the biological neurons, which transmit and received spike trains.\\

Finally, another Spatio-temporal classifiers or classifier's adaptations to deal with spatial and temporal EEG data are suggested to be explored. One example is the use of deep recurrent-convolutional neural networks as those in \cite{bashivan2015learning, tan2017multimodal, hajinoroozi2017deep}. Particularly in \cite{bashivan2015learning}, based on the channel's locations, the EEG signals are transformed into sequential RGB topographic images, in which each resulting matrix represents the energy of a particular sub-band. Thus, the convolutional network processes each image to pass it to the recurrent network, which extracts the temporal information if the sequences.